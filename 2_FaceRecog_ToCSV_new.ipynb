{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**DIY FACIAL RECOGNITION FILE CREATION**<BR>\n",
        "This file creates files to be used for DIY facial recognition.<br>\n",
        "In order to run, this script requires a folder full of files which the \"1_FinalProject_ImageProcessing.ipynb\" script should have placed into a folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "###################################################################################################\n",
        "# PACKAGES - there are some crazy installation requirements. Please read all comments in this block\n",
        "###################################################################################################\n",
        "\n",
        "# First, if you did not open this script from the zip file, you will want to get that zip file, too. \n",
        "#       It contains the folder structure and supporting xml and .dat files you will need to run this\n",
        "#       script. It also contains a copy of this file, but it may be an older copy. Compare them to \n",
        "#       make sure you are using the latest copy.  You can find and download the \"FaceRecog.zip\" file \n",
        "#       in this folder: https://drive.google.com/drive/folders/16TnIGZDvEkgtxH_HzDRiz_PhW2xkUUW6?usp=sharing\n",
        "\n",
        "# if you haven't already installed imutils, uncomment the next line:\n",
        "#!pip install imutils \n",
        "import imutils\n",
        "\n",
        "# Follow the advice here to install cmake on your machine: https://cmake.org/download/\n",
        "# Then install cmake into Python using !pip\n",
        "# uncomment the next line if you haven't already installed cmake\n",
        "#!pip install cmake \n",
        "\n",
        "# Next make sure that the path to the cmake bin folder is in your environment (system) variables\n",
        "# then download the dlib tar.gz file from: https://pypi.org/project/dlib/#files. Put the file into the same folder as this python script, and install it directly from that tar.gz file \n",
        "# uncomment the next line if you haven't already installed dlib\n",
        "#!pip install \"dlib-19.23.0.tar.gz\" \n",
        "\n",
        "# AFTER INSTALLING dlib ***YOU MUST*** RESTART YOUR MACHINE - OR MAYBE JUST COLAB !!!!!!!!!!!!!!\n",
        "# if that doesn't work, try installing dlib using conda\n",
        "# and know that I feel your pain. \n",
        "# Feel free to call Lei. He's pretty sharp. He'll know what to do! ;)\n",
        "import dlib \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from cv2 import imread\n",
        "import sys\n",
        "import os\n",
        "from shutil import move\n",
        "from scipy.spatial.distance import euclidean\n",
        "\n",
        "# predictive modeling\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# randomize the data\n",
        "import random\n",
        "\n",
        "import time\n",
        "import pathlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "###################################################################################################\n",
        "# SET LOCAL PATH VARIABLES\n",
        "# These are variables that you will probably need to modify so that they work on your local machine\n",
        "###################################################################################################\n",
        "\n",
        "# because I use dark mode, I use a contrasting color when printing text against the background. You can change this here\n",
        "textColor = \"#cccccc\"\n",
        "\n",
        "# optional, True if you want to save a copy of the b&w frame, with the points on each face, into the \"Points\" folder\n",
        "saveCopyOfSpottedImage = False\n",
        "# optional, True if you want a textual list of images that fail. The end up in the \"Failed\" folder, regardless.\n",
        "reportFailedImages = False\n",
        "\n",
        "# the number of images, minimum, we need per person for model testing\n",
        "targetImagesPerPerson = 110\n",
        "\n",
        "# percent of data set to use as train\n",
        "trainSplit = .80\n",
        "\n",
        "# where you stored the the classifier xml file. Download a copy from here: https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\n",
        "classifierPath = r\"D:\\Karl\\1 Syracuse Masters Program\\2022 - Winter\\IST 718\\Final Project\\haarcascade_frontalface_default.xml.txt\"\n",
        "\n",
        "# where you stored the shape predictor data file - different predictors located here: https://github.com/davisking/dlib-models\n",
        "# Predictor 1 from: https://github.com/davisking/dlib-models/blob/master/shape_predictor_68_face_landmarks.dat.bz2\n",
        "predictorPath = r\"D:\\Karl\\1 Syracuse Masters Program\\2022 - Winter\\IST 718\\Final Project\\shape_predictor_68_face_landmarks.dat\"\n",
        "# Predictor 2 (81% effective for random forest, ~47% Bayes, ~74% KNN) from: https://github.com/davisking/dlib-models/blob/master/shape_predictor_68_face_landmarks_GTX.dat.bz2\n",
        "# predictorPath = r\"D:\\Karl\\1 Syracuse Masters Program\\2022 - Winter\\IST 718\\Final Project\\shape_predictor_68_face_landmarks_GTX.dat\"\n",
        "\n",
        "# path where everything happens\n",
        "srcFolder = pathlib.Path(\"FaceRecog_FromCSV.ipynb\").parent.resolve()\n",
        "\n",
        "# starting point for random numbers\n",
        "seed = 121717874"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "####################################################################################\n",
        "# MORE LOCAL VARIABLES - you should probably leave these alone\n",
        "####################################################################################\n",
        "\n",
        "# path from which images get loaded\n",
        "toProcessPath = str(srcFolder) + \"\\\\ToProcess\"\n",
        "\n",
        "# paths to folders in which images get saved\n",
        "processedPath = str(srcFolder) + \"\\\\Processed\"\n",
        "failedPath = str(srcFolder) + \"\\\\Failed\"\n",
        "pointedImgPath = str(srcFolder) + \"\\\\Points\"\n",
        "\n",
        "# paths to files that get saved\n",
        "distancesSavePath = str(srcFolder) + \"\\\\Data\\\\distances.csv\"\n",
        "pointsSavePath = str(srcFolder) + \"\\\\Data\\\\points.csv\"\n",
        "trainSavePath = str(srcFolder) + \"\\\\Data\\\\train.csv\"\n",
        "testSavePath = str(srcFolder) + \"\\\\Data\\\\test.csv\"\n",
        "\n",
        "# files from which data may be pre-loaded (optional)\n",
        "pathToLoadDistances = str(srcFolder) + \"\\\\Data\\\\distances.csv\"\n",
        "preloadDistances = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "########################\n",
        "# DATA ACQUISITION TOOLS\n",
        "########################\n",
        "\n",
        "# completely customized but informed by https://livecodestream.dev/post/detecting-face-features-with-python/\n",
        "# shape predictor helps by locating important points on a face\n",
        "predictor = dlib.shape_predictor(predictorPath) \n",
        "\n",
        "# detects top, bottom, left, and right points on a face - the frame in which the other points sit\n",
        "detector = dlib.get_frontal_face_detector() # Load the detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "#################\n",
        "# HANDY FUNCTIONS\n",
        "#################\n",
        "\n",
        "# Extract the name of the person from the original file name\n",
        "def getPersonNameFromImgName(imgName):\n",
        "    fileNameSplit = imgName.split(\"_\")\n",
        "    return(fileNameSplit[0].replace(\" \", \"\"))\n",
        "\n",
        "# turns a landmarks point into a list of 2 points\n",
        "def cleanPoint(p):\n",
        "    return([p.x,p.y])\n",
        "\n",
        "# gets a list of all point lists\n",
        "# usage: getPoints(landmarks.parts())\n",
        "def getPoints(lParts):\n",
        "    lp = list(lParts)\n",
        "    xy = list(map(cleanPoint, lp))\n",
        "    return xy\n",
        "\n",
        "# if the filename passed in is a jpg, simply return the file name, otherwise, return None\n",
        "def getImgOrNone(fileName):\n",
        "    l = len(fileName)\n",
        "    if l > 4 and (fileName[l - 4:l]).lower() == \".jpg\":\n",
        "        return(fileName)\n",
        "    else:\n",
        "        return(None)\n",
        "\n",
        "def prependPath(fileName, path):\n",
        "    return path + \"\\\\\" + fileName\n",
        "\n",
        "# gets all jpg files from a folder\n",
        "def getImagesAndImageNames(folderPath):\n",
        "    # get all file names from the folder\n",
        "    allFiles = os.listdir(folderPath)\n",
        "\n",
        "    # remove all non-jpg files from the list\n",
        "    allFiles = list(map(getImgOrNone, allFiles))\n",
        "    allFileNames = os.listdir(toProcessPath)\n",
        "    processedFileNames = []\n",
        "\n",
        "    jpgFiles = []\n",
        "\n",
        "    # for every file in files\n",
        "    for i in range(0,len(allFiles)):\n",
        "        # get the name of the file\n",
        "        fName = allFileNames[i]\n",
        "        # get the image, if it's an image, otherwise, ignore the file or folder\n",
        "        if getImgOrNone(fName) != None:            \n",
        "            fileWithPath = prependPath(allFiles[i], folderPath)\n",
        "            thisFile = imread(fileWithPath)     # read the file\n",
        "            jpgFiles.append(thisFile)           # add the file to the list of files we want to store\n",
        "            processedFileNames.append(fName)    # add the name of the file to the list of file we want to store\n",
        "    \n",
        "    return [jpgFiles, processedFileNames]\n",
        "\n",
        "\n",
        "# returns points on the face. \n",
        "# The first 4 points are top, bottom, left, and right edges (not points at all)\n",
        "# The remaining 68 points are actually turned into slopes for \n",
        "def getFaceData(img, imgName):\n",
        "\n",
        "    showLeft = False\n",
        "    showRight = True\n",
        "    leftPoint = []\n",
        "    rightPoint = []\n",
        "\n",
        "    try:\n",
        "        # Convert into grayscale\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Detect faces\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "\n",
        "        # crop the image\n",
        "        x = faces[0][0]\n",
        "        y = faces[0][1]\n",
        "        w = faces[0][2]\n",
        "        h = faces[0][3]\n",
        "\n",
        "        # crop both the colored and gray images\n",
        "        cropped_color = img[y:y+h, x:x+w]\n",
        "        cropped_gray = gray[y:y+h, x:x+w]\n",
        "\n",
        "        # resize the image - https://www.tutorialkart.com/opencv/python/opencv-python-resize-image/\n",
        "        cropped_color = cv2.resize(cropped_color, (330,330), interpolation = cv2.INTER_AREA)\n",
        "        cropped_gray = cv2.resize(cropped_gray, (330,330), interpolation = cv2.INTER_AREA)\n",
        "        frame = detector(cropped_gray) # get the edges of the face\n",
        "    \n",
        "        tst = frame[0]\n",
        "    except:\n",
        "        move(prependPath(imgName, toProcessPath), prependPath(imgName, failedPath))\n",
        "\n",
        "    for f in frame:\n",
        "\n",
        "        # mark the landmarks\n",
        "        landmarks = predictor(image=cropped_gray, box=f)\n",
        "        x = landmarks.part(30).x\n",
        "        y = landmarks.part(30).y        \n",
        "        centerPoint = [x, y]  \n",
        "        if showRight:\n",
        "            x = landmarks.part(45).x\n",
        "            y = landmarks.part(45).y\n",
        "            rightPoint = [x, y]   \n",
        "        if showLeft:\n",
        "            x = landmarks.part(48).x\n",
        "            y = landmarks.part(48).y\n",
        "            leftPoint = [x, y]       \n",
        "\n",
        "        # gather x/y coords for each landmark point on image\n",
        "        for n in range(0, 68):\n",
        "\n",
        "            # get the x/y coords of each point\n",
        "            x = landmarks.part(n).x\n",
        "            y = landmarks.part(n).y\n",
        "\n",
        "            # informational commentary if we want to print each euclidean distance from nose\n",
        "            # print(\"Euclidean distance from nose: {}\".format(euclidean(centerPoint, [x,y])))\n",
        "\n",
        "            # Draw a circle\n",
        "            cv2.circle(img=cropped_gray, center=(x, y), radius=3, color=(0, 255, 0), thickness=-1)\n",
        "\n",
        "        \n",
        "        ####################################################################################\n",
        "        ###### optional, save spotted image ################################################\n",
        "        # change save/not save option in settings\n",
        "        if saveCopyOfSpottedImage:\n",
        "\n",
        "            bwFileName = \"z_\"+ imgName\n",
        "\n",
        "            # write spotted image to the source folder for inspection\n",
        "            cv2.imwrite(prependPath(fileName=bwFileName, path=pointedImgPath), cropped_gray)\n",
        "        ###### end optional ################################################################\n",
        "        ####################################################################################\n",
        "\n",
        "        # move file to processed\n",
        "        try:            \n",
        "            move(src=prependPath(fileName=imgName, path=toProcessPath), dst=processedPath)\n",
        "        except:\n",
        "            raise Exception(\"Failed to move {} to {}.\".format(imgName, processedPath))\n",
        "\n",
        "        points = getPoints(landmarks.parts())\n",
        "\n",
        "        # adds Euclidean distances from central point on face\n",
        "        distancesFromCenter = list(map(euclidean, points, centerPoint * (len(points)-1)))\n",
        "        distances = distancesFromCenter\n",
        "        \n",
        "        if showRight: # adds distances from point on right side of face\n",
        "            distancesFromRight = list(map(euclidean, points, rightPoint * (len(points)-1)))\n",
        "            distances = list(distances + distancesFromRight)\n",
        "        if showLeft: # adds distances from point on left side of face\n",
        "            distancesFromLeft = list(map(euclidean, points, leftPoint * (len(points)-1)))\n",
        "            distances = list(distances + distancesFromLeft)\n",
        "        \n",
        "\n",
        "        return points, distances\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Images that Fail to Load**<br>\n",
        "~34% of the images that we collected failed to load. The reasons for this ranges from dark images, obstructed, or partly obstructed, images and chaotic backgrounds that confuse CV2's algorithms. The project was designed to compensate for this by collecting more images than necessary. Some people were harder to read than others. It is clear why many of Joshua's images were difficult to read, as his face was half-obscured by the bottom of the screen. It is less obvious why the system had such a difficult time capturing, and then recognizing, Katie. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "h6XmfU0rM548",
        "outputId": "82ca5337-778d-4c2c-dc75-282fb5ae68f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distances being preloaded...\n"
          ]
        }
      ],
      "source": [
        "##########################################################################################################\n",
        "# TRANSFORMATION:   GET A TABLE OF ALL POINTS ON EACH FACE. ALSO...\n",
        "#                   GET A TABLE OF EUCLIDEAN DISTANCES FOR ALL POINTS ON EACH FACE TO THE TIP OF EACH NOSE\n",
        "##########################################################################################################\n",
        "\n",
        "if preloadDistances == False:\n",
        "    # code to detect where face is on the image\n",
        "    # https://towardsdatascience.com/face-detection-in-2-minutes-using-opencv-python-90f89d7c0f81\n",
        "    # Load the cascade classifier xml file\n",
        "    face_cascade = \"\"\n",
        "    try:\n",
        "        face_cascade = cv2.CascadeClassifier(classifierPath)\n",
        "    except:\n",
        "        # if it fails to load locally, try to get it from GitHub\n",
        "        face_cascade = \"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\"\n",
        "        print(\"Local classifier not found. Loading from GitHub.\")\n",
        "\n",
        "    # get all of the images we're processing, along with their file names\n",
        "    imgs, imgNames = getImagesAndImageNames(toProcessPath)\n",
        "\n",
        "    # a few variables we'll need below\n",
        "    savedImgNames = []\n",
        "    numberOfImagesToProcess = len(imgs)\n",
        "    allDistances = {}\n",
        "    allPoints = {}\n",
        "    isFirst = True\n",
        "    i = 0\n",
        "\n",
        "    # get points and euclidean distances for points on every image we're processing\n",
        "    for img in imgs: \n",
        "\n",
        "        # use the index number to get the name of the file we're saving, since the img, itself, doesn't carry a name\n",
        "        currentFileName = imgNames[i] \n",
        "\n",
        "        # try to get all point coordinates and euclidean distances for each file\n",
        "        try:\n",
        "            points, distances = getFaceData(img, currentFileName)\n",
        "\n",
        "            # if this is the first image we're processing, create the data structures\n",
        "            if isFirst:\n",
        "                allDistances = ([distances])\n",
        "                allPoints = ([points])\n",
        "                isFirst = False\n",
        "            else: # otherwise, just append the next data to the existing structures\n",
        "                allDistances.append(distances)\n",
        "                allPoints.append(points)\n",
        "\n",
        "            # make a note of the name of the image we just saved    \n",
        "            savedImgNames.append(currentFileName)\n",
        "        except:\n",
        "            if reportFailedImages:\n",
        "                print(\"getFaceData() failed for {}\".format(currentFileName))\n",
        "\n",
        "        i = i + 1\n",
        "\n",
        "    # save the points and Euclidean distances in dataframes\n",
        "    allDistances = pd.DataFrame(allDistances)\n",
        "    allPoints = pd.DataFrame(allPoints)\n",
        "\n",
        "    # rename distance columns\n",
        "    allDistances.columns = list(map(lambda oldColName: \"dist_\" + str(oldColName), allDistances.columns[0:len(allDistances.columns)])) # https://stackoverflow.com/questions/2050637/appending-the-same-string-to-a-list-of-strings-in-python\n",
        "    allDistances[\"img\"] = savedImgNames\n",
        "    allDistances[\"person\"] = allDistances[\"img\"].apply(getPersonNameFromImgName)\n",
        "    # rearrange distance columns\n",
        "    cols = [\"person\", \"img\"] + list(allDistances.columns[0:len(allDistances.columns)-2])\n",
        "    allDistances = allDistances[cols]\n",
        "\n",
        "    # rename points columns\n",
        "    allPoints.columns = list(map(lambda oldColName: \"dist_\" + str(oldColName), allPoints.columns[0:len(allPoints.columns)]))\n",
        "    allPoints[\"img\"] = savedImgNames\n",
        "    allPoints[\"person\"] = allPoints[\"img\"].apply(getPersonNameFromImgName)\n",
        "    # rearrange points columns\n",
        "    cols = [\"person\", \"img\"] + list(allPoints.columns[0:len(allPoints.columns)-2])\n",
        "    allPoints = allPoints[cols]\n",
        "\n",
        "    if numberOfImagesToProcess == 0:\n",
        "        raise Exception(\"Error: no files in the source folder: {}. Did you forget to put files into that folder?\".format(srcFolder))\n",
        "\n",
        "    print(\"{} images processed successfully! {} images failed to load. Please check `failed` folder to see failed images.\".format(len(savedImgNames), numberOfImagesToProcess - len(savedImgNames)))\n",
        "else:\n",
        "    print(\"Distances being preloaded...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "##############################################################################################\n",
        "# OPTIONAL: CAN BE SET AT TOP OF THIS SCRIPT SO THAT ALL DATA FROM EVERY PERSON CAN BE LOADED\n",
        "#           BECAUSE THIS SCRIPT IS BEING PASSED IN, WE ARE NOT INCLUDING ALL OF THE ORIGINAL\n",
        "#           IMAGE FILES. THAT WOULD BE FAR TO LARGE TO SUBMIT. INSTEAD, THIS FILE CAN BE USED\n",
        "#           TO SIMULATE THE LOADING OF ALL OF THE IMAGES\n",
        "##############################################################################################\n",
        "\n",
        "# get all data\n",
        "if preloadDistances:\n",
        "    allDistances = pd.read_csv(pathToLoadDistances)\n",
        "    newCols = allDistances.columns[1:len(allDistances.columns)] # remember the columns we want to keep\n",
        "    allDistances.set_index(\"Unnamed: 0\", inplace=False) # reset the index to the first column's values\n",
        "    allDistances = allDistances[newCols] # remove the old index column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\KETRE~1.WIN\\AppData\\Local\\Temp/ipykernel_38456/2965808394.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ad[\"person\"] = ad[\"person\"].apply(str.lower)        # change case of person to lower\n",
            "C:\\Users\\KETRE~1.WIN\\AppData\\Local\\Temp/ipykernel_38456/2965808394.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ad[\"person\"][ad[\"person\"] == \"sandras\"] = \"sandys\"\n",
            "C:\\Users\\ketre.WINDOWS-H8826EH\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\generic.py:8870: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return self._update_inplace(result)\n",
            "C:\\Users\\KETRE~1.WIN\\AppData\\Local\\Temp/ipykernel_38456/2965808394.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ad[\"person\"][ad[\"person\"] == \"andrew\"] = \"andrewd\"\n",
            "C:\\Users\\KETRE~1.WIN\\AppData\\Local\\Temp/ipykernel_38456/2965808394.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ad[\"person\"][ad[\"person\"] == \"anniet\"] = \"annieti\"\n",
            "C:\\Users\\KETRE~1.WIN\\AppData\\Local\\Temp/ipykernel_38456/2965808394.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ad[\"person\"][ad[\"person\"] == \"davidl\"] = \"davidla\"\n",
            "C:\\Users\\KETRE~1.WIN\\AppData\\Local\\Temp/ipykernel_38456/2965808394.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ad[\"person\"][ad[\"person\"] == \"garenm\"] = \"garenmo\"\n",
            "C:\\Users\\KETRE~1.WIN\\AppData\\Local\\Temp/ipykernel_38456/2965808394.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ad[\"person\"][ad[\"person\"] == \"jiebin\"] = \"jiebinz\"\n",
            "C:\\Users\\KETRE~1.WIN\\AppData\\Local\\Temp/ipykernel_38456/2965808394.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ad[\"person\"][ad[\"person\"] == \"joshua\"] = \"joshuab\"\n",
            "C:\\Users\\KETRE~1.WIN\\AppData\\Local\\Temp/ipykernel_38456/2965808394.py:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ad[\"person\"][ad[\"person\"] == \"karltr\"] = \"karltre\"\n",
            "C:\\Users\\KETRE~1.WIN\\AppData\\Local\\Temp/ipykernel_38456/2965808394.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ad[\"person\"][ad[\"person\"] == \"katieh\"] = \"katieha\"\n",
            "C:\\Users\\KETRE~1.WIN\\AppData\\Local\\Temp/ipykernel_38456/2965808394.py:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ad[\"person\"][ad[\"person\"] == \"leiche\"] = \"leichen\"\n",
            "C:\\Users\\KETRE~1.WIN\\AppData\\Local\\Temp/ipykernel_38456/2965808394.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ad[\"person\"][ad[\"person\"] == \"nickwa\"] = \"nickwai\"\n",
            "C:\\Users\\KETRE~1.WIN\\AppData\\Local\\Temp/ipykernel_38456/2965808394.py:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ad[\"person\"][ad[\"person\"] == \"noahla\"] = \"noahlar\"\n",
            "C:\\Users\\KETRE~1.WIN\\AppData\\Local\\Temp/ipykernel_38456/2965808394.py:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ad[\"person\"][ad[\"person\"] == \"noefer\"] = \"noefern\"\n",
            "C:\\Users\\KETRE~1.WIN\\AppData\\Local\\Temp/ipykernel_38456/2965808394.py:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ad[\"person\"][ad[\"person\"] == \"sethri\"] = \"sethris\"\n"
          ]
        }
      ],
      "source": [
        "########################################\n",
        "# SCRUB: CLEAN UP DIFFERENT PERSON NAMES\n",
        "########################################\n",
        "\n",
        "# determine which columns we really need\n",
        "colsToKeep = [\"person\"] + list(allDistances.columns[2:len(allDistances.columns)])\n",
        "\n",
        "ad = allDistances[colsToKeep]                       # get a local copy of allDistances df\n",
        "ad[\"person\"] = ad[\"person\"].apply(str.lower)        # change case of person to lower\n",
        "\n",
        "#print(ad[\"person\"].unique())                        # check out person names before\n",
        "# fix person names where they are duplicates\n",
        "ad[\"person\"][ad[\"person\"] == \"sandras\"] = \"sandys\"  \n",
        "ad[\"person\"][ad[\"person\"] == \"andrew\"] = \"andrewd\"  \n",
        "ad[\"person\"][ad[\"person\"] == \"anniet\"] = \"annieti\"  \n",
        "ad[\"person\"][ad[\"person\"] == \"davidl\"] = \"davidla\"  \n",
        "ad[\"person\"][ad[\"person\"] == \"garenm\"] = \"garenmo\"  \n",
        "ad[\"person\"][ad[\"person\"] == \"jiebin\"] = \"jiebinz\"  \n",
        "ad[\"person\"][ad[\"person\"] == \"joshua\"] = \"joshuab\"  \n",
        "ad[\"person\"][ad[\"person\"] == \"karltr\"] = \"karltre\"  \n",
        "ad[\"person\"][ad[\"person\"] == \"katieh\"] = \"katieha\"  \n",
        "ad[\"person\"][ad[\"person\"] == \"leiche\"] = \"leichen\"  \n",
        "ad[\"person\"][ad[\"person\"] == \"nickwa\"] = \"nickwai\"\n",
        "ad[\"person\"][ad[\"person\"] == \"noahla\"] = \"noahlar\"\n",
        "ad[\"person\"][ad[\"person\"] == \"noefer\"] = \"noefern\"\n",
        "ad[\"person\"][ad[\"person\"] == \"sethri\"] = \"sethris\"\n",
        "#print(ad[\"person\"].unique())                        # check out person names after"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>personID</th>\n",
              "      <th>dist_0</th>\n",
              "      <th>dist_1</th>\n",
              "      <th>dist_2</th>\n",
              "      <th>dist_3</th>\n",
              "      <th>dist_4</th>\n",
              "      <th>dist_5</th>\n",
              "      <th>dist_6</th>\n",
              "      <th>dist_7</th>\n",
              "      <th>dist_8</th>\n",
              "      <th>...</th>\n",
              "      <th>dist_126</th>\n",
              "      <th>dist_127</th>\n",
              "      <th>dist_128</th>\n",
              "      <th>dist_129</th>\n",
              "      <th>dist_130</th>\n",
              "      <th>dist_131</th>\n",
              "      <th>dist_132</th>\n",
              "      <th>dist_133</th>\n",
              "      <th>dist_134</th>\n",
              "      <th>dist_135</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>173.994253</td>\n",
              "      <td>187.856328</td>\n",
              "      <td>158.050625</td>\n",
              "      <td>178.241409</td>\n",
              "      <td>165.529454</td>\n",
              "      <td>170.815690</td>\n",
              "      <td>165.000000</td>\n",
              "      <td>155.080624</td>\n",
              "      <td>155.913438</td>\n",
              "      <td>...</td>\n",
              "      <td>111.305885</td>\n",
              "      <td>121.494856</td>\n",
              "      <td>142.284925</td>\n",
              "      <td>109.224539</td>\n",
              "      <td>90.022219</td>\n",
              "      <td>117.341382</td>\n",
              "      <td>50.089919</td>\n",
              "      <td>120.332872</td>\n",
              "      <td>92.195445</td>\n",
              "      <td>114.109596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>154.945152</td>\n",
              "      <td>181.231896</td>\n",
              "      <td>140.698259</td>\n",
              "      <td>170.064694</td>\n",
              "      <td>157.000000</td>\n",
              "      <td>169.446157</td>\n",
              "      <td>167.585799</td>\n",
              "      <td>157.292721</td>\n",
              "      <td>168.023808</td>\n",
              "      <td>...</td>\n",
              "      <td>111.198022</td>\n",
              "      <td>110.860272</td>\n",
              "      <td>129.003876</td>\n",
              "      <td>97.416631</td>\n",
              "      <td>91.197588</td>\n",
              "      <td>103.097042</td>\n",
              "      <td>62.096699</td>\n",
              "      <td>104.809351</td>\n",
              "      <td>94.429868</td>\n",
              "      <td>100.603181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>177.132719</td>\n",
              "      <td>189.763010</td>\n",
              "      <td>155.116086</td>\n",
              "      <td>175.262660</td>\n",
              "      <td>163.975608</td>\n",
              "      <td>171.723615</td>\n",
              "      <td>167.523133</td>\n",
              "      <td>156.064089</td>\n",
              "      <td>166.207701</td>\n",
              "      <td>...</td>\n",
              "      <td>101.833197</td>\n",
              "      <td>113.534136</td>\n",
              "      <td>129.034879</td>\n",
              "      <td>105.385008</td>\n",
              "      <td>86.005814</td>\n",
              "      <td>112.929181</td>\n",
              "      <td>52.345009</td>\n",
              "      <td>112.641023</td>\n",
              "      <td>87.005747</td>\n",
              "      <td>105.304321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>184.390889</td>\n",
              "      <td>195.601636</td>\n",
              "      <td>164.109719</td>\n",
              "      <td>181.727818</td>\n",
              "      <td>171.432202</td>\n",
              "      <td>179.724790</td>\n",
              "      <td>179.178682</td>\n",
              "      <td>166.709328</td>\n",
              "      <td>168.576392</td>\n",
              "      <td>...</td>\n",
              "      <td>105.990566</td>\n",
              "      <td>131.244047</td>\n",
              "      <td>128.097619</td>\n",
              "      <td>113.745330</td>\n",
              "      <td>87.051709</td>\n",
              "      <td>120.166551</td>\n",
              "      <td>55.901699</td>\n",
              "      <td>128.444541</td>\n",
              "      <td>88.814413</td>\n",
              "      <td>122.588743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>171.592541</td>\n",
              "      <td>195.058965</td>\n",
              "      <td>152.069063</td>\n",
              "      <td>176.638048</td>\n",
              "      <td>162.542302</td>\n",
              "      <td>171.420536</td>\n",
              "      <td>169.685002</td>\n",
              "      <td>153.495928</td>\n",
              "      <td>165.511329</td>\n",
              "      <td>...</td>\n",
              "      <td>95.603347</td>\n",
              "      <td>120.415946</td>\n",
              "      <td>117.613775</td>\n",
              "      <td>108.295891</td>\n",
              "      <td>79.762146</td>\n",
              "      <td>113.053085</td>\n",
              "      <td>50.596443</td>\n",
              "      <td>114.982607</td>\n",
              "      <td>80.062476</td>\n",
              "      <td>109.293184</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 137 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   personID      dist_0      dist_1      dist_2      dist_3      dist_4  \\\n",
              "0         0  173.994253  187.856328  158.050625  178.241409  165.529454   \n",
              "1         0  154.945152  181.231896  140.698259  170.064694  157.000000   \n",
              "2         0  177.132719  189.763010  155.116086  175.262660  163.975608   \n",
              "3         0  184.390889  195.601636  164.109719  181.727818  171.432202   \n",
              "4         0  171.592541  195.058965  152.069063  176.638048  162.542302   \n",
              "\n",
              "       dist_5      dist_6      dist_7      dist_8  ...    dist_126  \\\n",
              "0  170.815690  165.000000  155.080624  155.913438  ...  111.305885   \n",
              "1  169.446157  167.585799  157.292721  168.023808  ...  111.198022   \n",
              "2  171.723615  167.523133  156.064089  166.207701  ...  101.833197   \n",
              "3  179.724790  179.178682  166.709328  168.576392  ...  105.990566   \n",
              "4  171.420536  169.685002  153.495928  165.511329  ...   95.603347   \n",
              "\n",
              "     dist_127    dist_128    dist_129   dist_130    dist_131   dist_132  \\\n",
              "0  121.494856  142.284925  109.224539  90.022219  117.341382  50.089919   \n",
              "1  110.860272  129.003876   97.416631  91.197588  103.097042  62.096699   \n",
              "2  113.534136  129.034879  105.385008  86.005814  112.929181  52.345009   \n",
              "3  131.244047  128.097619  113.745330  87.051709  120.166551  55.901699   \n",
              "4  120.415946  117.613775  108.295891  79.762146  113.053085  50.596443   \n",
              "\n",
              "     dist_133   dist_134    dist_135  \n",
              "0  120.332872  92.195445  114.109596  \n",
              "1  104.809351  94.429868  100.603181  \n",
              "2  112.641023  87.005747  105.304321  \n",
              "3  128.444541  88.814413  122.588743  \n",
              "4  114.982607  80.062476  109.293184  \n",
              "\n",
              "[5 rows x 137 columns]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#####################################################\n",
        "# TRANSFORM:  TURN person COLUMN INTO personID COLUMN\n",
        "#####################################################\n",
        "\n",
        "ad = ad.sort_values(by=\"person\")                    # sort by person\n",
        "p = ad[\"person\"].unique()                           # get one copy of each person\n",
        "i = list(range(0,len(p)))                           # get an index for the table that will translate people into numbers\n",
        "pID = pd.DataFrame(data=p, index=i)\n",
        "pID.columns = [\"person\"]\n",
        "pID['personID'] = pID.index\n",
        "\n",
        "ad = pd.merge(ad, pID, how=\"inner\", on=\"person\")\n",
        "ad = ad[[\"personID\"] + list(ad.columns[1:len(ad.columns)-1])]\n",
        "\n",
        "# take a look at the transformed data frame\n",
        "ad.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We will remove 16 images from andrewd. Previous total was 126\n",
            "We will remove 31 images from annieti. Previous total was 141\n",
            "We will remove 4 images from christi. Previous total was 114\n",
            "We will remove 23 images from davidla. Previous total was 133\n",
            "We will remove 29 images from farahin. Previous total was 139\n",
            "We will remove 9 images from garenmo. Previous total was 119\n",
            "We will remove 121 images from jessika. Previous total was 231\n",
            "We will remove 151 images from jiebinz. Previous total was 261\n",
            "We will remove 143 images from jonfox. Previous total was 253\n",
            "We will remove 16 images from joshuab. Previous total was 126\n",
            "We will remove 426 images from karltre. Previous total was 536\n",
            "We will remove 263 images from katieha. Previous total was 373\n",
            "We will remove 114 images from leichen. Previous total was 224\n",
            "We will remove 88 images from matthew. Previous total was 198\n",
            "We will remove 59 images from nickwai. Previous total was 169\n",
            "We will remove 154 images from noahlar. Previous total was 264\n",
            "We will remove 152 images from noefern. Previous total was 262\n",
            "We will remove 123 images from sandys. Previous total was 233\n",
            "We will remove 104 images from sethris. Previous total was 214\n",
            "We will remove 16 images from sherhon. Previous total was 126\n",
            "\n",
            "\n",
            "All images were removed for the following individuals due to insufficient number of images:\n",
            "     person  personID\n",
            "6   jackson         6\n",
            "19  sarahgo        19\n"
          ]
        }
      ],
      "source": [
        "#####################################################################\n",
        "# SCRUB: REMOVE ANY PERSONS WHO DON'T HAVE A MINIMUM NUMBER OF IMAGES\n",
        "#####################################################################\n",
        "\n",
        "personsRemoved = pID.copy(deep=True)\n",
        "\n",
        "# for each person, make sure there are a minimum number of images\n",
        "for i in pID[\"personID\"]:\n",
        "    # get the number of images we have for this person\n",
        "    c = len(ad[ad[\"personID\"] == i])\n",
        "    # if we have fewer than the minimum number, remove that person from the data\n",
        "    if c < targetImagesPerPerson: \n",
        "        ad = ad[ad[\"personID\"] != i]\n",
        "    else: \n",
        "        # otherwise, note down the fact that they won't have their image removed\n",
        "        personsRemoved = personsRemoved[personsRemoved[\"personID\"] != i]\n",
        "        # get ids we'll cull (and leave as many as we need to build a good model)\n",
        "        imagesToCull = random.sample(list(ad.index[ad[\"personID\"] == i]), c-targetImagesPerPerson)\n",
        "        \n",
        "        prsn = pID[\"person\"][i]\n",
        "\n",
        "        print(\"We will remove {} images from {}. Previous total was {}\".format(len(imagesToCull), prsn, c))\n",
        "        # remove the extra images\n",
        "        ad.drop(imagesToCull, inplace=True)\n",
        "\n",
        "\n",
        "print(\"\\n\\nAll images were removed for the following individuals due to insufficient number of images:\\n{}\".format(personsRemoved))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "########################################\n",
        "# GET TRAIN AND TEST SETS FOR THE MODELS\n",
        "########################################\n",
        "\n",
        "random.seed(seed)\n",
        "\n",
        "try:\n",
        "    ad = ad.reset_index(drop=True)\n",
        "except:\n",
        "    print(\"No need to reset index. Already exists.\")\n",
        "\n",
        "results = []\n",
        "predictions = []\n",
        "\n",
        "c = len(ad) # get the length of the dataframe\n",
        "\n",
        "#############################################################\n",
        "# get train/test split with equal number of images per person\n",
        "#############################################################\n",
        "trainDist = pd.DataFrame()\n",
        "testDist = pd.DataFrame()\n",
        "\n",
        "\n",
        "# for each person in the dataframe, get 75% of their images\n",
        "for i in pID.index:\n",
        "\n",
        "    personSample = ad.loc[ad[\"personID\"] == i] # first, get all the images of that person\n",
        "    \n",
        "    # assuming there are some images\n",
        "    if(len(personSample)) > 0:     \n",
        "        # get a random list of indexes for our train set\n",
        "        randList = random.sample(range(personSample.index[0], (personSample.index[0] + targetImagesPerPerson)), int(targetImagesPerPerson * trainSplit))\n",
        "\n",
        "        # get the train and test tables\n",
        "        trainDist = trainDist.append(ad.iloc[randList])\n",
        "        testDist = testDist.append(ad.iloc[list(set(personSample.index) - set(randList))]) # https://stackoverflow.com/questions/3462143/get-difference-between-two-lists\n",
        "\n",
        "# fix the indexes on the train and test tables\n",
        "trainDist - trainDist.reset_index(drop=True)\n",
        "testDist - testDist.reset_index(drop=True)\n",
        "\n",
        "# separate train into x and y variables \n",
        "y_train = trainDist[\"personID\"]\n",
        "X_train = trainDist[trainDist.columns[2:len(trainDist.columns)]]\n",
        "\n",
        "# separate test into x and y variables \n",
        "y_test = testDist[\"personID\"]\n",
        "X_test = testDist[testDist.columns[2:len(testDist.columns)]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save all distances to file\n",
        "if preloadDistances == False: # if we didn't preload the distances from a file, save new distances\n",
        "    allDistances.to_csv(distancesSavePath)\n",
        "# save all points to file - NOT WORKABLE YET. NEEDS POINTS TO BE CHANGED TO SPARSE ARRAY\n",
        "#allPoints.to_csv(pointsSavePath)\n",
        "\n",
        "# save train/test data to csv file \n",
        "# NOTE: IF YOU DO THIS, YOU WILL NEED TO CHANGE THE bestRandomForestSeed VARIABLE IN THE latest FaceRecog_FromCSV.jpynb file\n",
        "trainDist.to_csv(trainSavePath)\n",
        "testDist.to_csv(testSavePath)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "FaceRecog.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
